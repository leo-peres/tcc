\section{Complexidade computacional} \label{section_computational_complexity}

Na seção anterior nós vimos que Turing nos deu uma definição formal do que nós intuitivamente pensamos ser computável. Porém, no mundo real, um problema ter um processo computacional finito que o resolva não é suficiente. Também queremos que a computação seja feita num tempo que seja útil para nós. O que foi observado é que o tempo de execução de algoritmos em computadores cresce a medida em que o tamanho da entrada também cresce. Pense no tamanho da entrada sendo medido como, por exemplo, o número de bits na representação binária de um número ou o número de vértices em um grafo. Como normalmente é desejável que um algoritmo seja eficiente para entradas de tamanho razoavelmente grande (em alguns casos o tamanho da entrada pode ser $10^6$, por exemplo), nós queremos que a função de crescimento do algoritmo não cresça muito rápidamente --- para que até para entradas de tamanho ``razoavelmente grande'' o número de passos necessários para realizar o algoritmo não seja excessivamente grande. Portanto foi importante definir uma forma de medir a complexidade de algoritmos e também o que nos queremos dizer por uma "função eficiente" para o tempo de execução de um algoritmo.

Talvez o primeiro artigo que definiu uma medida de complexidade para problema computacionais foi~\cite{hartmanis1965computational}, onde Hartmarnis e Stearns definiram que uma sequência binária $\alpha$ é computável em tempo $T$, onde $T$ é uma função computável monotônica crescente de $\mathbb{N}$ para $\mathbb{N}$, se existe uma máquina de Turing que dá como saída o n-ésimo bit de $\alpha$ em menos do que $T(n)$ passos. Em \cite{edmonds1965paths}, Edmonds propõe que devemos considerar funções polinomiais como sendo sinônimo de eficiência.

Nós dizemos que uma máquina de Turing $M$ roda em tempo $T(n)$ se $M$, ao receber uma entrada de tamanho $n$, executa no máximo $T(n)$ passos (um passo da computação da máquina de Turing envolve escrever símbolos em suas fitas de trabalho, movimentar os cabeçotes de suas fitas e mudar o seu estado atual). Ao longo deste trabalho nós vamos assumir que esta função $T$ e qualquer outra função que estivermos usando para medir a complexidade de um problema computacional é \emph{tempo-construtível} da forma definida a seguir.

\begin{defi} [Funções tempo-construtíveis] \label{time_constructive_functions}

Uma função $f: \mathbb{N} \to \mathbb{N}$ é dita ser tempo-construtível se existe uma máquina de Turing $M_{f}$ que ao receber a string unária $1^{n}$ em sua entrada, $M_{f}$ escreve a representação binária de $f(n)$ em sua fita de saída em $\mathcal{O}(f(n))$ passos.

\end{defi}

Todas funções que nos interessam como as funções polinomiais, $\log n$, $2^{n^{c}}$, etc. são tempo construtíveis.

Nós vimos no teorema~\ref{teo:MTuni1} que existe uma máquina de Turing que pode simular a execução de todas as outras máquinas de Turing sobre qualquer entrada. Também foi dito que a simulação é ``eficiente'' e que segundo Edmonds isto deveria significar que a simulação pode ser feito em tempo polinomial. E nós podemos verificar que o número de passos que $\mathcal{U}$ precisa para simular uma máquina de Turing $M$ de tempo $T(n)$ é $\mathcal{O}(T(n)^{2})$. Para provar isto temos que ver quanto passos $\mathcal{U}$ necessita para simular um único passo de $M$. Em cada simulação de um passo, $\mathcal{U}$ visita cada ``espaço'' que representa uma fita de $M$, e como uma computação que executa menos do que $T(n)$ passos não pode usar mais do que $T(n)$ células de sua fita, temos que cada espaço contém no máximo $T(n)$ células. Então para simular um passo de $M$, $\mathcal{U}$ visita algo em torno de $kT(n)$ células de sua fita de trabalho, onde $k$ é o número de fitas de $M$, e portanto o ``slowdown'' de simular $M$ é apenas $\mathcal{O}(T(n))$.

Nós podemos fazer melhor do que $T(n)^{2}$, nós podemos simular uma máquina de Turing com ``slowdown'' logarítmico.

\begin{teo} \label{teo:MTuni2}

Existe uma máquina de Turing $~\mathcal{U}^{*}$ que sobre a entrada $(\alpha, x)$, $~\mathcal{U}^{*}$ dá como saída $M_{\alpha}(x)$. Além disso, se $T(\lvert x \rvert)$ é o tempo que $M_{\alpha}$ leva para executar sua computação sobre a entrada $x$, então $\mathcal{U}^{*}$ roda em tempo $\mathcal{O}(T(\lvert x \rvert)\log T(\lvert x \rvert))$ ao receber $(\alpha, x)$ em sua fita de entrada.

\end{teo}

Uma prova do teorema \ref{teo:MTuni2} pode ser encontrada em~\cite{arora2009computational} (Teorema 1.9). O resultado foi originalmente proposto por Hennie e Stearns~\cite{hennie1966two}.

%Em algum lugar aqui falar de máquinas de Turing oblivous

Construindo sobre o resultado acima nós podemos provar o seguinte resultado que nos será útil mais para frente.

\begin{defi} \label{defi: oblivious}

Uma máquina de Turing \emph{oblivious} é uma máquina de Turing cuja o movimento de seus cabeçotes de fita só dependem do tamanho da entrada, e não no conteúdo das células e o estado atual.

\end{defi}

Desta forma, a função de transição de uma máquina de Turing \emph{oblivious} $A = \{\Gamma, Q, \delta\}$ de $k$ fitas é $\delta: Q \times \Gamma^{k} \to Q \times \Gamma^{k - 1}$. Nós podemos imaginar que existe uma função $m: \mathbb{N} \to \{\{E, N, D\}^{k}\}^{*}$ tal que ao receber uma entrada $x$, os movimentos dos cabeçotes das fitas de $A$ é dado por $m(\lvert x \rvert) = (z_{1}, \dots, z_{T(\lvert x \rvert)})$, onde cada $z_{i} \in \{E, N, D\}^{k}$ representa os movimentos dos cabeçotes de fita de $A$ no $i$-ésimo passo e $T(\lvert x \rvert)$ é o tempo em que $A$ para ao receber entradas de tamanho $\lvert x \rvert$.

\begin{teo}

Se $M$ é uma máquina de Turing que roda em tempo $T(n)$ para entradas de tamanho $n$, então existe uma máquina de Turing \emph{oblivious} $A$ de duas fitas que roda em tempo $\mathcal{O}(T(n)\log T(n))$ tal que $A(x) = M(x)$, para todo $x \in \{0, 1\}^{*}$.

\end{teo}

\begin{proof}

Nós podemos modificar a MT $\mathcal{U}^{*}$ no teorema~\ref{teo:MTuni2} de forma que ela seja uma máquina de Turing \emph{oblivious} sem aumentar significativamente o seu tempo de execução. E além disso, $\mathcal{U}^{*}$ pode ser construida usando somente 2 fitas.

Então, $A$ simplesmente executa a simulação de $\mathcal{U}^{*}$ sobre entradas $(\langle M \rangle, x)$, para qualquer $x \in \{0, 1\}^{*}$.

\end{proof}

Uma das contribuições de Hartmanis e Stearns em~\cite{hartmanis1965computational} foi que eles mostraram como podemos agrupar problemas computacionais de acordo com o número de passos que um máquina de Turing necessita para resolvê-los. Nesta seção iremos nos preocupar apenas com o tempo e espaço necessários para resolver problemas computacionais. Algumas classes de complexidade de tempo são definidas a seguir, e no fim desta seção iremos ver algumas classes de complexidade de espaço.

\begin{defi}

Para uma função $T: \mathbb{N} \to \mathbb{N}$, nós definimos as seguintes classes de problemas:

\begin{itemize}

\item $\text{\DTIME}(T(n))$: a classe de todas linguagens $L$ tal que existe uma máquina de Turing determinística $M$ de tempo $T(n)$ que decide $L$.

\item $\text{\NTIME}(T(n))$: a classe de todas linguagens $L$ tal que existe uma máquina de Turing não-determinística $N$ que decide $L$ e $N$ executa no máximo $T(n)$ passos ao receber uma entrada de tamanho $n$, indepedente das escolhas das funções de transição de $N$.

\item $\text{\co\DTIME}(T(n))$: a classe de todas linguagens $L$ tal que $\overline{L} \in \text{\DTIME}(T(n))$, onde $\overline{L}$ é o complemento da linguagem $L$ (ou seja, $x \in L \iff x \notin \overline{L}$). Da mesma forma nós definimos $\text{\co\NTIME}(T(n))$.

\end{itemize}

\end{defi}


\subsubsection{As classes $\P$ e $\NP$}

%Devo apresentar a classe P

Como já vimos, iremos usar tempo polinomial como sinônimo de eficiência. Uma linguagem $L$ é decidida em tempo polinomial se existe um polinômio $p$ tal que o tempo necessário para decidir a pertinência de uma string $x$ em $L$ é menor do que $p(\lvert x \rvert)$. A classe de linguagens decididas em tempo polinomial é chamada de $\P$.

\begin{defi} [A classe $\P$]

Uma linguagem $L$ é dita estar em $\P$ se e somente se existe $c \geq 1$ tal que $L \in \text{\DTIME}(n^{c}$).

\end{defi}

Um dos grandes objetivos de designers de algoritmos é provar que um determinado problema está em $\P$ pois então geralmente ele pode ser implementado eficientemente em um computador. Alguém poderia dizer que talvez exista um problema (natural) que esteja em $\P$ mas o tempo de execução do algoritmo para este problema é algo do tipo $10^{1000}n$ ou $n^{1000}$, o que com certeza não seria eficiente nem mesmo para $n = 2$. É verdade que um problema estar em $\P$ não implica necessariamente em ele poder ser resolvido eficientemente. Na verdade, nem mesmo a não existência de um algoritmo de tempo polinomial para um problema implica em ele não poder ser resolvido eficientemente na prática. Mas usar a convenção de tempo polinomial = eficiência é conveniente quando estamos estudando classes de complexidade e a relação entre elas, por alguns motivos como por exemplo algumas modificações na definição de máquinas de Turing e até mesmo outros modelos computacionais mais realistas (como máquinas de acesso aleatório) não alteram a classe $\P$, entre outros motivos.

%NP

Enquanto que $\P$ procura capturar linguagens que podem ser decididas eficientemente, a classe $\NP$ por sua vez procura capturar linguagens cuja suas instâncias sejam eficientemente verificáveis.

\begin{defi} [A classe $\NP$]

Uma linguagem $L$ está em $\NP$ se e somente se existe um polinômio $p$ e uma máquina de Turing de tempo polinomial $M$ tal que $x \in L \iff \exists u \in \{0, 1\}^{p(\lvert x \rvert)} M(x, u) = 1$. 

\end{defi}

Dizemos que $u$ é um certificado da pertinência de $x$ em $L$. Nós podemos definir $\NP$ de uma outra forma:

\begin{defi}

$\NP = \bigcup_{c \geq 1} \NTIME(n^{c})$.

\end{defi}

Para ver que as duas definições são equivalentes note que as escolhas da máquina de Turing não-determinística podem servir como um certificado, enquanto que uma máquina de Turing não-determinística poderia ``adivinhar'' um certificado para $x$.



A questão em aberto mais importante em complexidade computacional pergunta se as classes $\P$ e $\NP$ são iguais. Esse problema tem alguma importância histórica já que vários problemas que são importante em aplicações práticas que estão em $\NP$ não parecem, pelo que sabemos até agora, ter solução melhor do que tentar exaustivamente todas as possibilidades, a busca por uma solução para esses problemas melhor do que a busca exaustiva esteve no coração de algumas das primeiras pesquisas em complexidade computacional.

\begin{defi} [A classe $\co\NP$]

$\co\NP = \bigcup_{c \geq 1} \co\NTIME(n^{c})$.

\end{defi}

Note que $\P$ = $\co\P$, já que um procedimento que decide eficientemente a pertinência de uma \emph{string} em uma linguagem também pode ser usada para decidir a não pertinência (simplesmente inverta a saída), e portanto $\P = \NP$ implica em $\NP = \co\NP$.

%Reduções
\subsubsection{Reduções}

Um dos principais conceitos em teoria da computação é o de uma \emph{redução}. Uma redução é basicamente um procedimento que transforma uma instância de um problema $A$ em uma instância de um outro problema $B$.

\begin{defi} [Reduções] \label{defi:reducoes}

Uma redução de um problema $L \subseteq \{0, 1\}^{*}$ para um problema $L^{\prime} \subseteq \{0, 1\}^{*}$ é uma função $f: \{0, 1\}^{*} \to \{0, 1\}^{*}$ tal que $x \in L \iff f(x) \in L^{\prime}$, para todo $x \in \{0, 1\}^{*}$.

Além disso, $L$ é dita ser redutível em tempo polinomial para $L^{\prime}$, o que denotamos por $L \leq_{p} L^{\prime}$, se a redução $f$ pode ser computada em tempo polinomial.

\end{defi}

Reduções de tempo polinomial vão ser útil quando formos ver o próximo assunto. Se $L$ é redutível em tempo polinomial para $L^{\prime}$, então um algoritmo de tempo polinomial para $L^{\prime}$ implica em um algoritmo de tempo polinomial para $L$, já que podemos usar a redução $f$ para mapear uma string $x \in \{0, 1\}^{*}$ em uma instâcia $f(x)$ de $L^{\prime}$ e depois usamos o algoritmo $A$ de tempo polinomial que decida $L^{\prime}$ para computar $A(f(x))$. Se o tempo necessário para computar $A$ sobre entradas de tamanho $n$ for $p(n)$, onde $p$ é um polinômio, e $q$ for o tempo necessário para computar $f$ então acabamos de mostrar que podemos decidir $L$ em tempo menor do que $q(\lvert x \rvert) + p(q(\lvert x \rvert))$. 

%NP-completude e teorema de Cook-Levin

\subsubsection{$\NP$-completude e o teorema de Cook-Levin}

Algumas linguagens em uma determinada classe de complexidade tem uma propriedade interessante em que elas capturam toda a dificuldade daquela classe. Um linguagem $L$ é completa para uma classe sobre uma determinada ``classe de reduções'' $\leq_{R}$ (por exemplo, reduções em tempo polinomial como vimos na definição~\ref{defi:reducoes}) se ela pertence à classe e todos os outros problemas dentro desta classe são redutíveis através de $\leq_{R}$ para $L$.

\begin{defi} [$\NP$-completude] \label{defi:NPC}

Uma linguagem $L$ é dita ser $\NP$-difícil sse para todas linguagens $A \in \NP$, $A \leq_{p} L$.

Se além de ser $\NP$-difícil $L$ também está em $\NP$ então dizemos que $L$ é $\NP$-completa.

\end{defi}

Problemas $\NP$-completos (que sejam naturais) existem, como foi provado por Stephen Cook e Leonid Levin, independentemente, no começo da década de 70.~\cite{cook1971complexity, levin1973universal} O primeiro problema que foi provado ser $\NP$-completo foi o problema da satisfazibilidade booleana.

\begin{defi} [O problema da satisfazibilidade booleana] \label{defi:SAT}

No problema da satisfazibilidade booleana, que chamaremos de $\SAT$, é dado uma fórmula $\phi$ com variáveis $x_{1}, \dots, x_{n}$ e queremos de decidir se existe uma atribuição $(x_{1}^{\prime}, \dots, x_{n}^{\prime})$ às variáves $x_{1}, \dots, x_{n}$ tal que $\phi(x_{1}^{\prime}, \dots, x_{n}^{\prime}) = 1$.

\end{defi}

\begin{teo} [Teorema de Cook-Levin] \label{teo:cooklevin}

$\SAT$ é $\NP$-completo.

\end{teo}

Apesar de poder ser um pouco longa, a prova do teorema \ref{teo:cooklevin} é bem simples de entender. Basicamente, nós temos que se $A$ é uma linguagem em $\NP$, então existe uma máquina de Turing $M$ (que podemos assumir ter apenas uma fita) que aceita uma entrada $x \in \{0, 1\}^{n}$ com um certificado $u \in \{0, 1\}^{\text{poly}(n)}$ se e somente se $x \in A$ e $u$ é um certificado da pertinência de $x$ em $A$. A função $f: \{0, 1\}^{*} \to \{0, 1\}^{*}$
que transforma $x$ em uma fórmula $\phi_{x}$ que é satisfazível se e somente se $x \in A$ faz o seguinte:

\begin{enumerate}

\item Se para todo $n > 0$ $M$ roda em tempo menor do que $T(n)$ sobre entradas de tamanho $n$ então $f$ constroi um tableau $T(\lvert x \rvert) \times T(\lvert x \rvert)$ onde a $i$-ésima linha deste tableau guardará a configuração de $M$ no seu $i$-ésimo passo.

\item A fórmula $\phi_{x}$ tem $T(\lvert x \rvert)^{2}$ variáveis que chamaremos de $v_{ij}$, $1 \leq i, j \leq T(\lvert x \rvert)$. O valor da variável $v_{ij}$ é o conteúdo da célula na linha $i$ e coluna $j$ do tableau. 

\item Pela computação de uma máquina de Turing ser local, o que significa dizer que o conteúdo de uma das células em um passo da computação depende somente do estado atual, da posição do cabeçote da fita e do conteúdo das duas células adjacente à ela, podemos construir uma fórmula booleana que decide o valor da variável $v_{ij}$ em função das variáveis $v_{(i - 1)(j - 1)}, v_{(i - 1)j}$ e $v_{(i - 1)(j + 1)}$. Esta fórmula depende somente da função de transição de $M$ e portanto tem tamanho constante.

\item Precisamos assegurar algumas outras coisas, como por exemplo que a primeira linha do tableau é uma configuração inicial válida e que a última linha é uma configuração de aceitação (isto é, uma configuração onde o estado atual é $q_{aceita}$).

\end{enumerate}

Pela natureza ``repetitiva'' da redução e pela fórmula ter tamanho polinomial ($\mathcal{O}(T(n)^{2})$) podemos ver que ela pode ser feita em tempo polinomial. Finalmente, $\text{SAT} \in \NP$ já que uma atribuição das variáveis que satisfazem uma fórmula pode servir como certificado.

Agora que nós temos um único problema que sabemos ser $\NP$-completo, nós podemos provar que outros problemas são também $\NP$-completo mostrando que $\SAT$ é redutível em tempo polinomial para eles. Isso segue pois a relação $\leq_{p}$ é transitiva. Por exemplo, podemos provar que a linguagem 3-$\SAT$, que pergunta se uma fórmula na 3-FNC é satisfazível, é $\NP$-completa. Em 1972, Richard Karp publicou~\cite{karp1972reducibility} onde 21 problemas importantes foram provados serem $\NP$-completos e deste então milhares de problemas que aparecem em aplicações práticas já foram provados serem $\NP$-completos. O livro de Garey e Johnson é uma excelente referência para o fenômeno da $\NP$-completude.~\cite{garey2002computers}

Como já observamos antes, se existe uma linguagem $\NP$-completa em $\P$ então $\P$ = $\NP$, pois poderiamos usar a redução de tempo polinomial para $L$ e depois o seu algoritmo de tempo polinomial para decidir qualquer outra linguagem em $\NP$ em tempo polinomial.

%SAT e ETH

%Intratabilidade (ou seja, teorema de hierarquias)

%Complexidade de espaço

%Problemas PSPACE-completos e EXP-completos

%Hierarquia polinomial (incluir em algum lugar máquinas de Turing alternantes)

\subsubsection{Hierarquia polinomial}

Considere o seguinte problema em $\NP$:

\begin{clique}

Dado um inteiro $k > 0$ e um grafo $G$, aceite se $G$ tem um clique de tamanho maior ou igual a $k$.

\end{clique}

Podemos ver que $\CLIQUE$ está em $\NP$ pois um clique de tamanho maior ou igual a $k$ em $G$ é obviamente um certificado que $G$ tem um clique de tamanho maior ou igual a $k$. Mas se ao invés de decidir se $G$ tem um clique de tamanho pelo menos $k$ nós queremos decidir se o maior clique em $G$ tem tamanho $k$, como no problema $\MAXCLIQUE$:

\begin{maxclique}

Dado um inteiro $k > 0$ e um grafo $G$, aceite se o maior clique em $G$ tem tamanho igual a $k$.

\end{maxclique}

Agora não fica tão óbvio para nós o que seria um certificado para $\MAXCLIQUE$. Além de termos que mostrar um clique de tamanho $k$, também devemos mostrar que nenhum subconjunto de tamanho maior do que $k$ dos vértices de $G$ formam um clique. Porém, adicionando um quantificador $\forall$ parece ser o suficiente para nós podermos capturar problemas como $\MAXCLIQUE$, o que a classe $\NP$ não parece conseguir fazer pelo o que nós sabemos até agora.

\begin{defi} [A classe $\Sigma_{2}^{p}$]

Uma linguagem $L$ é dita estar em $\Sigma_{2}^{p}$ se e somente se existe um polinômio $p$ e uma máquina de Turing $M$ que roda em tempo $p(n)$ tal que $L$ pode ser escrita como:

\begin{equation*}
    \text{Para todo } x \in \{0, 1\}^{*} \text{, } x \in L \iff \exists x_{1} \in \{0, 1\}^{p(\lvert x \rvert)} \forall x_{2} \in \{0, 1\}^{p(\lvert x \rvert)} M(x, x_{1}, x_{2}) = 1
\end{equation*}

\end{defi}

Se as instâncias $\MAXCLIQUE$ são da forma $\langle G, k \rangle$, onde $G$ é um grafo e $k > 0$ um inteiro, então dizer $\langle G, k \rangle \in \MAXCLIQUE$ é o mesmo que dizer que \emph{existe} um clique de tamanho $k$ e que \emph{todos} subconjuntos de tamanho maior do que $k$ dos vértices de $G$ não formam um clique.

Nós podemos ainda generalizar as classes $\NP$ e $\Sigma_{2}^{p}$, o que nós chamamos de hierarquia polinomial:

\begin{defi} [Hierarquia polinomial] \label{defi: PH}

Para $k \geq 1$, uma linguagem $L$ é dita estar em $\Sigma_{k}^{p}$ se $L$ pode ser expressa da seguinte forma:

\begin{equation*}
    x \in L \iff \exists x_{1} \in \{0, 1\}^{p(\lvert x \rvert)} \forall x_{2} \in \{0, 1\}^{p(\lvert x \rvert)} \dots Q_{k} x_{k} \in \{0, 1\}^{p(\lvert x \rvert)} M(x, x_{1}, x_{2}, \dots, x_{k}) = 1
\end{equation*}

Onde $Q_{k}$ é $\exists$ se $k$ é ímpar ou $\forall$ se $k$ é par. $M$ é uma máquina de Turing de tempo $p(n)$.

A hierarquia polinomial é $\PH$ = $\bigcup_{k \geq 1} \Sigma_{k}^{p}$.

\end{defi}

Note que $\NP$ = $\Sigma_{1}^{p}$ e também podemos chamar $\P$ de $\Sigma_{0}^{p}$.

Assim como fizemos com $\NP$, também podemos generilizar a classe $\co\NP$ através de quantificadores alternantes. A diferença é que o primeiro quantificador é um $\forall$.

\begin{defi}

Para todo $k \geq 1$ a classe $\co\Sigma_{k}^{p}$ consiste de todas as linguagens $L$ que podem ser expressas como:

\begin{equation*}
    x \in L \iff \forall x_{1} \in \{0, 1\}^{p(\lvert x \rvert)} \exists x_{2} \in \{0, 1\}^{p(\lvert x \rvert)} \dots Q_{k} x_{k} \in \{0, 1\}^{p(\lvert x \rvert)} M(x, x_{1}, x_{2}, \dots, x_{k})
\end{equation*}

Onde agora $Q_{k}$ é $\forall$ se $k$ é ímpar e $\exists$ caso contrário. E de novo, $M$ é uma máquina de Turing de tempo $p(n)$. Para cada $k$, nós chamamos $\co\Sigma_{k}^{p}$ de $\Pi_{k}^{p}$.

\end{defi}

E nós temos que $\co\NP = \Pi_{1}^{p}$.

É fácil ver que para todo $k \geq 1$ nós temos as seguintes desigualdades:

\begin{equation*}
    \Sigma_{k}^{p} \subseteq \Pi_{k + 1}^{p} \subseteq \Sigma_{k + 2}^{p}
\end{equation*}

Portanto $\PH = \bigcup_{k \geq 1} \Pi_{k}^{p}$

Nós dizemos que a hierarquia polinomial \emph{colapsa} se para algum $k$, $\PH = \Sigma_{k}^{p}$. Neste caso dizemos que a hierarquia polinomial colapsa para o seu $k$-ésimo level e também temos que $\Sigma_{k}^{p} = \Sigma_{l}^{p}$, para todo $l > k$.

\begin{teo} \label{teo: phcollapse}

Para todo $k \geq 1$, se $\Sigma_{k}^{p} = \Pi_{k}^{p}$ então $\PH = \Sigma_{k}^{p}$.

\end{teo}

\begin{proof}

\hfill

Assuma que para algum $k \geq 1$, $\Sigma_{k}^{p} = \Pi_{k}^{p}$.

Nós mostramos por indução que para todo $l > k$, $\Sigma_{l}^{p} = \Pi_{l}^{p} = \Sigma_{k}^{p}$. Para isso só precisamos mostrar que $\Sigma_{l}^{p} \subseteq \Sigma_{k}^{p}$, pois por nós termos assumido que $\Sigma_{k}^{p} = \Pi_{k}^{p}$, $\Sigma_{l}^{p} = \Sigma_{k}^{p}$ implica em $\Sigma_{l}^{p}$ estar fechada sob complemento.

Para $l = k + 1$, nós temos que toda linguagem $L$ em $\Sigma_{k + 1}^{p}$ pode ser expressa como:

\begin{equation} \label{eq:phcolapse1}
    x \in L \iff \exists x_{1} \in \{0, 1\}^{p(\lvert x \rvert)} \forall x_{2} \in \{0, 1\}^{p(\lvert x \rvert)} \dots Q_{k + 1} x_{k + 1} \{0, 1\}^{p(\lvert x \rvert)} M(x, x_{1}, x_{2}, \dots, x_{k + 1}) = 1
\end{equation}

para alguma polinômio $p$ e máquina de Turing de tempo polinomial $M$.

Então considere a seguinte linguagem $L^{\prime}$:

\begin{equation*}
    (x, x_{1}) \in L^{\prime} \iff \forall x_{2} \in \{0, 1\}^{p(\lvert x \rvert)} \dots Q_{k + 1} x_{k + 1} \{0, 1\}^{p(\lvert x \rvert)} M(x, x_{1}, x_{2}, \dots, x_{k + 1}) = 1
\end{equation*}

$L^{\prime}$ está em $\Pi_{k}^{p} = \Sigma_{k}^{p}$ portanto podemos reescrever $L^{\prime}$ como:

\begin{equation} \label{eq:phcolapse2}
    (x, x_{1}) \in L^{\prime} \iff \exists y_{1} \in \{0, 1\}^{p(\lvert x \rvert)} \forall y_{2} \in \{0, 1\}^{p(\lvert x \rvert)} \dots Q_{k} x_{k} \in \{0, 1\}^{p(\lvert x \rvert)} M^{\prime}(x, x_{1}, y_{1}, y_{2}, \dots, y_{k}) = 1
\end{equation}

Então podemos trocar toda parte a partir do primeiro quantificador $\forall$ de~\ref{eq:phcolapse1} pelo lado direito de~\ref{eq:phcolapse2} e temos o seguinte:

\begin{equation*}
    x \in L \iff \exists x_{1}, y_{1} \in \{0, 1\}^{p(\lvert x \rvert)} \forall y_{2} \in \{0, 1\}^{p(\lvert x \rvert)} \dots Q_{k} y_{k} \in \{0, 1\}^{p(\lvert x \rvert)} M^{\prime}(x, x_{1}, y_{1}, y_{2}, \dots, y_{k}) = 1
\end{equation*}


Portanto $L \in \Sigma_{k}^{p}$.

Para provar para outros valores de $l > k + 1$, nós provamos da mesma maneira mas assumindo que $\Sigma_{l - 1}^{p} = \Pi_{l - 1}^{p}$ que agora sabemos que são iguais a $\Sigma_{k}^{p}$.

\end{proof}

Assim como vimos que a classe $\NP$ tem problemas completos, podemos provar que cada level da hierarquia tem seu próprio problema completo. Uma linguagem $L$ é $\Sigma_{k}^{p}$-completa se e somente se $L \in \Sigma_{k}^{p}$ e para todo $L^{\prime} \in \Sigma_{k}^{p}$, $L^{\prime} \leq_{p} L$.  

Cada level da hierarquia polinomial tem a sua própria versão do problema $\SAT$.

\begin{defi}

Para todo $k > 0$, a linguagem $\Sigma_{k}^{p}\SAT$ consiste de todas as fórmulas lógicas $\phi$ tal que:

\begin{equation*}
    \exists u_{1} \in \{0, 1\}^{p(\lvert \langle \phi \rangle \rvert)} \forall u_{2} \in \{0, 1\}^{p(\lvert \langle \phi \rangle \rvert)} \exists \dots Q_{k} u_{k} \in \{0, 1\}^{p(\lvert \langle \phi \rangle \rvert)} \phi(u_{1}, u_{2}, \dots, u_{k})
\end{equation*}

é verdadeiro, onde $Q_{k}$ é $\exists$ se $k$ é ímpar e $\forall$ se $k$ é par.

Da mesma forma, uma fórmula lógica está em $\Pi_{k}^{p}\SAT$ se e somente o seguinte predicato quantificado é verdadeiro:

\begin{equation*}
    \forall u_{1} \in \{0, 1\}^{p(\lvert \langle \phi \rangle \rvert)} \exists u_{2} \in \{0, 1\}^{p(\lvert \langle \phi \rangle \rvert)} \forall \dots Q_{k} u_{k} \in \{0, 1\}^{p(\lvert \langle \phi \rangle \rvert)} \phi(u_{1}, u_{2}, \dots, u_{k})
\end{equation*}

Onde $Q_{k}$ é $\forall$ se $k$ é ímpar e $\exists$ se $k$ é par.

\end{defi}

E como é de se esperar, cada $\Sigma_{k}^{p}\SAT$ é $\Sigma_{k}^{p}$-completo. A prova que $\Pi_{k}^{p}\SAT$ é $\Pi_{k}^{p}$-completo, para cada $k \geq 1$, é análoga.

\begin{teo}

Para todo $k \geq 1$, $\Sigma_{k}^{p}\SAT$ é $\Sigma_{k}^{p}$-completo.

\end{teo}

\begin{proof}

Para algum $k \geq 1$, seja $L$ uma linguagem em $\Sigma_{k}^{p}$. Para toda string $x^{\prime} \in \{0, 1\}^{*}$, nós temos que mostrar que existe uma redução em tempo polinomial que transforma $x^{\prime}$ em uma instância $\phi_{x^{\prime}}$ de $\Sigma_{k}^{p}\SAT$ tal que $\phi_{x^{\prime}} \in \Sigma_{k}^{p}\SAT \iff x^{\prime} \in L$. Sabemos que podemos expressar $L$ como:

\begin{equation*}
    x \in L \iff \exists x_{1} \in \{0, 1\}^{p(\lvert x \rvert)} \forall x_{2} \in \{0, 1\}^{p(\lvert x \rvert)} \exists \dots Q_{k} x_{k} \in \{0, 1\}^{p(\lvert x \rvert)} M(x, x_{1}, x_{2}, \dots, x_{k}) = 1
\end{equation*}

Usando a redução do teorema~\ref{teo:cooklevin}, nós podemos transformar a máquina de Turing $M$ em uma fórmula $\phi$ tal que $\phi(x, x_{1}, x_{2}, \dots, x_{k}) = 1 \iff M(x, x_{1}, x_{2}, \dots, x_{k}) = 1$ em tempo polinomial. Para cada $x^{\prime} \in \{0, 1\}^{*}$ nós criamos a fórmula $\phi_{x^{\prime}}(x_{1}, x_{2}, \dots, x_{k}) = \phi(x^{\prime}, x_{1}, x_{2}, \dots, x_{k})$ e temos que

\begin{equation*}
    \exists x_{1} \in \{0, 1\}^{p(\lvert x \rvert)} \forall x_{2} \in \{0, 1\}^{p(\lvert x \rvert)} \exists \dots Q_{k} x_{k} \in \{0, 1\}^{p(\lvert x \rvert)} \phi_{x^{\prime}}(x_{1}, x_{2}, \dots, x_{k})
\end{equation*}

é verdade se e somente se

\begin{equation*}
     \exists x_{1} \in \{0, 1\}^{p(\lvert x \rvert)} \forall x_{2} \in \{0, 1\}^{p(\lvert x \rvert)} \exists \dots Q_{k} x_{k} \in \{0, 1\}^{p(\lvert x \rvert)} M(x^{\prime}, x_{1}, x_{2}, \dots, x_{k})
\end{equation*}

também é verdade. Ou seja, $\phi_{x^{\prime}} \in \Sigma_{k}^{p}\SAT$ se e somente se $x^{\prime} \in L$, como queriamos mostrar.

\end{proof}

\subsubsection{Complexidade de espaço}

Além de tempo, uma outra medida de complexidade de máquinas de Turing importante é o número de células da fita de trabalho utilizadas, o que denominamos por complexidade de espaço. Analogamente a como fizemos para complexidade de tempo, nós definimos classes de complexidade que agrupam problemas de acordo com a sua complexidade de espaço. Ao definir classes de complexidade para problemas que usam menos do que $S(n)$ células nós iremos assumir que a função $S(n)$ é espaço construtível, que é definidada de forma análoga a como definimos funções tempo-construtível.

\begin{defi} [Funções espaço-construtíveis] \label{space_constructible_functions_defi}

    Uma função $f: \mathbb{N} \to \mathbb{N}$ é dita ser espaço-construtível se existe uma máquina de Turing $M_{f}$ tal que ao receber a string unária $1^{n}$ em sua entrada, $M_{f}$ escreve a representação binária de $f(n)$ em sua fita de saída e utiliza $\mathcal{O}(f(n))$ células da sua fita de trabalho.

\end{defi}

De novo temos que todas as funções que iremos usar ao longo deste trabalho para descrever a complexidade de espaço de uma máquina de Turing são espaço-contrutíveis. Então definimos classes de complexidade de espaço da seguinte forma.

\begin{defi} [Classes de complexidade de espaço] \label{space_complexity_classes_defi}

    Para uma função (espaço-construtível) $S: \mathbb{N} \to \mathbb{N}$ nós definimos as seguintes classes de complexidade de espaço.

    \begin{itemize}
    
        \item $\SPACE(S(n))$: a classe de todas as linguangens $L$ tais que existe uma máquina de Turing determinística $M$ que decide $L$ em complexidade de espaço $S(n)$.
        
        \item $\NSPACE(S(n)$: a classe de todas as linguagens $L$ tais que existe uma máquina de Turing não-determinística $N$ que decide $L$ e todos os possíveis ramos da computação de $N$ computam em complexidade de espaço $S(n)$.
        
        \item $\co\SPACE(S(n))$: uma linguagem $L$ é dita estar em $\co\SPACE(S(n))$ se e somente se a linguagem $\overline{L}$ está em $\SPACE(S(n))$. Também podemos definir $\co\NSPACE(S(n))$ de forma similar.       
        
    \end{itemize}

\end{defi}

Nós então podemos definir a classe de problemas com complexidade de espaço polinomial.

\begin{defi} [A classe $\PSPACE$] \label{pspace_defi}

    A classe $\PSPACE$ é $\bigcup_{c > 0} \SPACE(n^{c})$. Ou seja, uma linguagem $L$ está em $\PSPACE$ se e somente se $L \in \SPACE(n^{c})$, para algum $c > 0$.

\end{defi}

A classe $\PSPACE$ é a versão da classe $\P$ para complexidade de espaço. Da mesma forma também temos a versão $\NP$ de complexidade de espaço que é a classe $\NPSPACE$.

\begin{defi} [A classe $\NPSPACE$] \label{npspace_defi}

    $\NPSPACE = \bigcup_{c > 0} \NTIME(n^{c})$.

\end{defi}

Nós temos que $P \subseteq \PSPACE$ pois uma máquina de Turing que para após um número polinomial de passos só pode ter usado um número polinomial de células da sua fita de trabalho. Indo na outra direção, temos que $\PSPACE \subseteq \bigcup_{c > 0} \DTIME(2^{n^{c}})$ (mais pra frente iremos ver que isto pode ser denotado como $\PSPACE \subseteq \EXP$) pelo seguinte argumento. Cada passo de uma máquina de Turing que usa apenas um número polinomial de células da sua fita de trabalho pode ser descrito por uma configuração usando um número polinomial de bits que iremos denotar por $n^{c}$, para algum $c > 0$. No entanto, por se tratar de uma máquina de Turing determinística temos que se ela repetir alguma das possívels $2^{n^{c}}$ configurações ela necessariamente entrou em um loop infinito. Como estamos considerando máquinas de Turing que param após um número finito de passos temos que isto não pode acontecer e portanto há de ser o caso que a máquina de Turing pare após no máximo $2^{n^{c}}$ passos.

Da mesma forma temos que $\NP \subseteq \PSPACE$ pois podemos reutilizar a fita de trabalho para simular cada escolha não-determinística, e também $\NPSPACE \subseteq \bigcup_{c > 0} \SPACE(2^{n^{c}})$ (equivalentemente, $\NPSPACE \subseteq \EXP$) pelo mesmo argumento que usamos para mostrar que $\PSPACE \subseteq \bigcup_{c > 0} \DTIME(2^{n^{c}})$. Na verdade, no caso geral temos que

\begin{equation} \label{space_complexity_relations}
    \DTIME(S(n)) \subseteq \NTIME(S(n)) \subseteq \SPACE(S(n)) \subseteq \NSPACE(S(n)) \subseteq \DTIME(2^{\mathcal{O}(S(n))}).
\end{equation}

O fato que máquinas de Turing podem reutilizar as células de sua fita de trabalho pode ser usada para generalizar a afirmação $\NP \subseteq \PSPACE$ para $\PH \subseteq \PSPACE$. 

\begin{teo} \label{ph_subset_pspace}

$\PH \subseteq \PSPACE$.

\end{teo}

\begin{proof}

    Seja $L \in \Sigma_{k}^{p}$, para algum $k > 0$. temos então que existe uma máquina de Turing $M$ que roda em tempo $p(n)$ tal que $L$ pode ser descrita da seguinte forma. Para todo $x \in \binalph^{n}$,
    
    \begin{equation*}
        x \in L \iff \exists z_{1} \in \binalph^{p(n)} \forall x_{2} \in \binalph^{p(n)} \dots Q_{k} z_{k} \in \binalph^{p(n)} M(x, z_{1}, z_{2}, \dots, z_{k}) = 1. 
    \end{equation*}
    
    Então podemos construir uma máquina de Turing que usa não mais do que $\mathcal{O}(p(n))$ células de sua fita de trabalho que verifica se existe alguma escolha $z_{1}^{\prime}$ para a string $z_{1}$ tal que
    
    \begin{equation*}
        \exists z_{1}^{\prime} \in \binalph^{p(n)} \forall x_{2} \in \binalph^{p(n)} \dots Q_{k} z_{k} \in \binalph^{p(n)} M(x, z_{1}, z_{2}, \dots, z_{k}) = 1.
    \end{equation*}

    Para cada escolha de $z_{1}$, $M^{\prime}$ pode reutilizar o espaço de sua fita de trabalho então o espaço que $M^{\prime}$ usa ao todo é simplesmente o espaço que ela usa para uma única escolha de $z_{1}$. O que basicamente estamos fazendo é descrever um procedimento recursivo, então podemos desenrolar a recursão e ver que o espaço utilizado é o espaço necessário para guardar as atribuições para as strings $z_{1}, z_{2}, \dots, z_{k}$ mais o espaço para simular a execução de $M$. Temos que ambos o termo são $\mathcal{O}(p(n)$ e portanto $M^{\prime}$ tem complexidade de espaço $\mathcal{O}(p(n))$. Portanto podemos concluir que $L \in \PSPACE$.

\end{proof}

Nós podemos usar o argumento acima para argumentar que a seguinte linguagem está em $\PSPACE$.

\begin{defi} \label{tbqf_defi}

    Seja $\TBQF$ a linguagem que contém todas as fórmulas livres de quantificadores $\phi$ tais que
    
    \begin{equation*}
        Q_{1} x_{1} Q_{2} x_{2} \dots Q_{n} x_{n} \phi(x_{1}, x_{2}, \dots, x_{n}) = 1,    
    \end{equation*}
    
    onde cada $Q_{i}$ é $\exists$ ou $\forall$.

\end{defi}

Não só temos que $\TBQF$ está em $\PSPACE$ mas também é verdade que $\TBQF$ é $\PSPACE$-completa.

\begin{defi} [Linguagens $\PSPACE$-completas] \label{pspace_complete_defi}

    Uma linguagem $L$ é dita ser $\PSPACE$-difícil se existe uma máquina de Turing $R$ que roda em tempo polinomial e para toda linguagem $L^{\prime} \in \PSPACE$,
    
    \begin{equation*}
        x \in L^{\prime} \iff R(x) \in L.
    \end{equation*}

    Se também for o caso que $L \in \PSPACE$ então dizemos que $L$ é $\PSPACE$-completa.

\end{defi}

Então agora mostramos que $\TBQF$ é $\PSPACE$-completa. Em \ref{ph_subset_pspace} nós vimos que $\TBQF \in \PSPACE$ então agora basta mostrar que $\TBQF$ é $\PSPACE$-difícil. Ou seja, só precisamos mostrar que para toda linguagem $L \in \PSPACE$, $L$ é redutível em tempo polinomial para $\TBQF$.

\begin{teo} \label{tbqf_pspace_complete}

    A linguagem $\TBQF$ é $\PSPACE$-completa.

\end{teo}

\begin{proof}

\end{proof}

Nós definimos complexidade de espaço como sendo a quantidade de células da \emph{fita de trabalho} que uma máquina de Turing utliza durante a sua computação. Portanto, nada nos impede de definir classes de complexidade para funções sublineares. Por exemplo, uma classe de complexidade importante é a classe de todos os problemas com complexidade de espaço logaritmico.

\begin{defi} [As classes $\L$ e $\NL$.] \label{l_nl_defi}

    Uma linguagem $L$ é dita estar em $\L$ se existe uma máquina de Turing $M$ com complexidade de espaço $\mathcal{O}(\log n)$ que decide $L$. Ou seja, $\L = \SPACE(\log n)$.
    
    Uma linguagem $L$ é dita estar em $\NL$ se existe uma máquina de Turing $N$ com complexidade de espaço não-determinística $\mathcal{O}(\log n)$ que decide $L$. Ou seja, $\NL = \NSPACE(\log n)$.

\end{defi}

A partir de \ref{space_complexity_relations} podemos afirmar que $\L \subseteq \NL \subseteq \SPACE(2^{\mathcal{O}(\log n)}) = \P$. Ainda é um problema em aberto se $\P \subseteq \NL$ o que implicaria em $\P = \NL$~\footnote{Também não se sabe se $\L = \NL$, no entanto o teorema de Savitch~\cite{savitch1970relationships} afirma que $\SPACE(S(n)) = \NSPACE(S(n)^{2})$ para funções $S(n) \geq \log n$, o que implica em, por exemplo, $\PSPACE = \NPSPACE$.}.

Nós podemos definir linguagens $\NL$-completas usando o seguinte tipo de reduções.

\begin{defi} [Reduções logspace] \label{logspace_reductions}

    Seja $L, L^{\prime}$. Nós dizemos que $L$ é logspace-redutível à $L^{\prime}$ se existe uma redução $f$ tal que $x \in L \iff f(x) \in L^{\prime}$ e além disso, existe uma máquina de Turing $R$ com complexidade de espaço $\mathcal{O}(\log n)$ que satisfaz o seguinte. Para todo $\langle x, i \rangle$ em que $x \in \binalph^{*}$ e $i \in \mathbb{N}$, ao receber $\langle x, i \rangle$ em sua entrada, $R$:

    \begin{enumerate}
    
        \item Rejeita a entrada se $i > \lvert f(x) \rvert$.
        
        \item Dá como saída o bit $f(x)_{i}$ e mais um bit indicando que a entrada $\langle x, i \rangle$ não foi rejeitada caso $1 \leq i \leq \lvert f(x) \rvert$. 
    
    \end{enumerate}

\end{defi}

Nós podemos provar que se redefinirmos problemas $\NP$-completos usando reduções logspaces então a linguagem $\SAT$ continua sendo $\NP$-completa. A idéia é usar o fato que a redução de Cook-Levin é estruturada de maneira bem repetitiva, então podemos calcular a partir do tamanho da entrada $x$ da redução o bit que aparece na $i$-ésima fórmula que resultou da redução se escolhermos uma codificação apropriada para a fórmula.

\begin{prop} [$\SAT$ é $\NP$-completa com respeito a reduções logspace] \label{sat_logspace_reduction}

    Vamos dizer que uma linguagem $L^{\prime}$ é $\NP$-completa se $L^{\prime} \in \NP$ e toda linguagem $L \in \NP$ é logspace-redutível à $L^{\prime}$. Então, sob esta definição de $\NP$-completude a linguagem $\SAT$ é $\NP$-completa.

\end{prop}

\begin{proof}

\end{proof}

\subsubsection{Classes de complexidade de tempo exponencial}

\subsubsection{Teoremas de hierarquia}

Como foi dito na introdução, um dos principais desafios da complexidade computacional é demonstrar limites inferiores para problemas computacionais. Intuitivamente podemos acreditar que problemas intrinsecamente difíceis devem existir pois se dermos mais recursos para uma máquina de Turing computar deveriamos também sermos capaz de decidir mais linguagens. Os teoremas de hierarquia é uma série de teoremas que provam exatamente isso. Geralmente, iremos usar o fato que máquinas de Turing que usam mais tempo podem simular máquinas de Turing que usam menos tempo para montar uma máquina de Turing ``diagonalizadora'', e então mostramos que esta máquina deve discordar com todas as máquinas que usam menos tempo em pelo menos um ponto.


\begin{teo} (Teorema da hierarquia de tempo determinístico~\cite{hartmanis1965computational}) \label{dtime_hierarchy}

Para todas funções $f, g: \mathbb{N} \to \mathbb{N}$ tempo-construtíveis satisfazendo $g(n)\log g(n) = o(f(n))$, temos que $\DTIME(g(n)) \subsetneq \DTIME(f(n))$.

\end{teo}

\begin{proof}

Seja $L \in \DTIME(g(n))$, note que pelo teorema \ref{teo:MTuni2} existe uma máquina de Turing que simula a execução de uma máquina de Turing que decide $L$ em tempo $\mathcal{O}(g(n)\log g(n)) = o(f(n))$. Então temos que deve existir uma máquina de Turing $\mathcal{D}$ que funciona da seguinte maneira:

\begin{itemize}

\item Sobre a entrada $\langle M \rangle$:

\item Simule $M$ sobre a entrada $\langle M \rangle$ por $g(\lvert \langle M \rangle \rvert)$ passos.

\item Se em algum momento $M$ aceita, rejeite a entrada; caso contrário, aceite.

\end{itemize} 

Note que $\mathcal{D}$ roda em tempo $\mathcal{O}(g(n)\log g(n))$ e portanto $L(\mathcal{D}) \in \DTIME(f(n))$.

Nós afirmamos que $L(\mathcal{D}) \notin \DTIME(g(n))$. Assuma o contrário, que $L(\mathcal{D}) \in \DTIME(g(n))$ e chame de $\mathcal{D}^{\prime}$ uma máquina de Turing que decida $L(\mathcal{D})$ em tempo $g(n)$. Então usamos o mesmo argumento que usamos para mostrar que $\HALT$ não é decidível para mostrar que $L(\mathcal{D}) \notin \DTIME(g(n))$ (ou equivalentemente, que tal máquina de Turing $\mathcal{D}^{\prime}$ não pode existir): nós rodamos $\mathcal{D}^{\prime}$ sobre a sua própria descrição e vemos o que acontece.

\begin{itemize}

\item Se $\mathcal{D}^{\prime}(\langle \mathcal{D}^{\prime} \rangle) = 1$ então $\mathcal{D}$ pela sua definição deve rejeitar a entrada $\langle \mathcal{D}^{\prime} \rangle \Rightarrow \mathcal{D}(\langle \mathcal{D}^{\prime} \rangle) = 0$

\item Se $\mathcal{D}^{\prime}(\langle \mathcal{D}^{\prime} \rangle) = 0$ então $\mathcal{D}$ aceita a entrada $\langle \mathcal{D} \rangle \Rightarrow \mathcal{D}(\langle \mathcal{D}^{\prime} \rangle) = 1$

\end{itemize}

Nos dois itens acima nós temos que assumir que a descrição de $\mathcal{D}^{\prime}$ seja grande o suficiente para que $D$ possa simular a toda a tua execução sobre a entrada $\langle \mathcal{D}^{\prime} \rangle$, mas isso não é problema já que $D^{\prime}$ possui descrições arbitrariamente grandes.

Ambos os casos são contradições e portanto temos que $L(\mathcal{D}) \not\in \DTIME(g(n))$ e $\DTIME(g(n)) \subsetneq \DTIME(f(n))$.

\end{proof}

Agora nós vamos considerar o caso não-determinístico. Se tentarmos provar da mesma forma um teorema de hierarquia de tempo não-determinístico nós esbarrariamos no seguinte problema: não é óbvio o modo como podemos negar uma computação não-determinística, pois deveriamos ter um conhecimento ''universal`` sobre todas os ramos da computação. A única forma óbvia de fazer isso seria simular todos os ramos da computação, o que leva tempo exponencial. Porém, ainda pode-se usar essa simulação determinística para diagonalizar máquinas de Turing não-determinística, dado que a simulação seja feita numa entrada exponencialmente menor do que a entrada original. O truque é fazer que uma máquina ''diagonalizadora`` $\mathcal{D}$ ou discorde de uma máquina de Turing não-determinística $M$ em alguma string unária de tamanho em um intervalo de comprimento exponencial ou que ela discorde nos extremos deste intervalo. Na prova do teorema abaixo nós usamos o fato que uma simulação não-deterministica pode ser feita com ''slowdown`` constante.

\begin{teo} (Teorema da hierarquia de tempo não-determinístico~\cite{cook1973hierarchy})

Sejam $f, g: \mathbb{N} \to \mathbb{N}$ funções tempo-construtíveis satisfazendo $g(n + 1) = o(f(n))$, então $\NTIME(g(n)) \subsetneq \NTIME(f(n))$.

\end{teo}

\begin{proof}

Nesta prova, $\{M_{i}\}_{i \in \mathbb{N}}$ representa uma enumeração de todas as máquinas de Turing não-determinísticas.

Considere a função $h$ definida como $h(1) = 2$ e $h(i + 1) = 2^{g(h(i) + 1)}$, para $i > 1$. Nós construimos uma máquina de Turing não-determinística $\mathcal{D}$ que inicialmente assumismo concordar com $M_{i}$ em todas as strings unárias $1^{n}$ satisfazendo $h(i) < n \leq h(i + 1)$, daí ela diagonaliza na entrada $1^{h(i + 1)}$ e a partir disso nós obtemos uma contradição. Como $h(i + 1)$ é exponencialmente maior do que $h(i) + 1$, $\mathcal{D}$ pode simular todos os ramos da computação de $M_{i}$ sobre a entrada $1^{h(i) + 1}$ deterministicamente. A máquina de Turing $\mathcal{D}$ é definida da seguinte maneira (qualquer entrada que não seja da forma $1^{n}$ para $n \in \mathbb{N}$ é imediatamente rejeitada):

\begin{enumerate}

\item Sobre a entrada $1^{n}$, ache $i$ tal que $h(i) < n \leq h(i + 1)$.

\item Se $h(i) < n < h(i + 1)$, $\mathcal{D}$ não-deterministicamente simula $M_{i}$ sobre a entrada $1^{n + 1}$ por $g(n + 1)$ passos e aceita se e somente se $M_{i}$ aceita.

\item Se $n = h(i + 1)$, $\mathcal{D}$ deterministicamente simula $M_{i}$ sobre a entrada $1^{h(i) + 1}$ por $g(h(i) + 1)$ passos e aceita se e somente se $M_{i}$ rejeita.

\end{enumerate}

Primeiro, nós temos que $\mathcal{D}$ roda em tempo não-determinístico $\mathcal{O}(f(n))$, pois estamos assumindo que $g(n + 1) = o(f(n))$. Vamos assumir que exista uma máquina de Turing não-determinística $\mathcal{D}^{\prime}$ que roda em tempo $\mathcal{O}(g(n))$ e $L(\mathcal{D}^{\prime}) = L(\mathcal{D})$. Seja $i$ suficientemente grande tal que $\mathcal{D}^{\prime} = M_{i}$. Se existe algum $h(i) < n \leq h(i + 1)$ tal que $\mathcal{D}^{\prime}(1^{n}) \neq \mathcal{D}(1^{n})$  então estamos feitos. Caso contrário, considere a entrada $1^{h(i + 1)}$. Nós temos o seguinte.

\begin{itemize}

    \item Se $\mathcal{D}^{\prime}(1^{h(i) + 1}) = 1$ então $\mathcal{D}$ deve rejeitar a entrada $1^{h(i + 1)}$.
    
    \item Se $\mathcal{D}^{\prime}(1^{h(i) + 1}) = 0$ então $\mathcal{D}$ deve aceitar a entrada $1^{h(i + 1)}$.

\end{itemize}

Então se quisermos evitar uma contradição precisamos ter $\mathcal{D}^{\prime}(1^{h(i) + 1}) \neq \mathcal{D}(1^{h(i + 1)})$. Mas temos pelo item (2) na descrição de $\mathcal{D}$ e pela nossa suposição que

\begin{equation*}
    \mathcal{D}^{\prime}(1^{h(i) + 1}) = \mathcal{D}(1^{h(i) + 2}) = \mathcal{D}^{\prime}(1^{h(i) + 2}) = \mathcal{D}(1^{h(i) + 3}) = \dots = \mathcal{D}^{\prime}(1^{h(i + 1) - 1}) = \mathcal{D}(1^{h(i + 1)}).
\end{equation*}

E portanto temos uma contradição.

\end{proof}

\subsubsection{Limites da diagonalização}

Podemos nos perguntar se a estratégia de diagonalização usadas nas provas dos teoremas de hierarquia pode também nos dar limites inferiores mais interessantes. Podemos separar as classes $\P$ e $\NP$ usando diagonalização?

Vamos imaginar que nós temos uma prova que $\P \neq \NP$ que usa diagonalização da forma que usamos para provar o teoremas de hierarquia. Ou seja, nós temos uma máquina de Turing $\mathcal{D}$ construida de forma que ela difere de todas as máquina de Turing $M$ ``em $\P$'' em pelo menos um ponto, simulando a execução de $M$ e depois invertendo a saída de $M$ sobre alguma entrada. Como podemos também enumerar e simular máquinas de Turing com qualquer oráculo $\mathcal{O}$ da mesma forma que podemos enumerar e simular máquinas de Turing convencionais, ao adicionar o oráculo $\mathcal{O}$ à $\mathcal{D}$ nós podemos também separar $\mathcal{D}^{\mathcal{O}}$ de todas as outras máquinas de Turing em $\P^{\mathcal{O}}$ de forma análoga. Portanto, uma prova que $\P \neq \NP$ que usa diagonalização deve também provar que $\P^{\mathcal{O}} \neq \NP^{\mathcal{O}}$. Porém, o objetivo desta seção é mostrar que existem oráculos $\mathcal{A}$ e $\mathcal{B}$ tal que $\P^{\mathcal{A}} = \NP^{\mathcal{A}}$ e $\P^{\mathcal{B}} \neq \NP^{\mathcal{B}}$.

\begin{teo} \label{teo: bgs}

Existem oráculos $\mathcal{A}$ e $\mathcal{B}$ tais que:

\begin{enumerate}

\item $\P^{\mathcal{A}} = \NP^{\mathcal{A}}$.

\item $\P^{\mathcal{B}} \neq \NP^{\mathcal{B}}$.

\end{enumerate}

\end{teo}

\begin{proof}

Para provar 1 nós fazemos $\mathcal{A}$ ser um oráculo para a linguagem $\PSPACE$-completa $\TBQF$. Daí, por simulações, nós temos que

\begin{equation*}
	\P^{\TBQF} \subseteq \NP^{\TBQF} \subseteq \PSPACE,
\end{equation*}

e por redução,

\begin{equation*}
	\PSPACE \subseteq \P^{\TBQF}
\end{equation*}

O oráculo $B$ nós vamos contruí-lo de forma que nenhuma máquina de Turing que executa menos do que $2^{n}/10$ passos possa decidir a linguagem $L_{\mathcal{B}}$ definida como

\begin{equation*}
    L_{\mathcal{B}} = \{1^{n} \lvert \exists y \in \mathcal{B} \text{ tal que } \lvert y \rvert = n \}
\end{equation*}

Note que $L_{\mathcal{B}} \in \NP^{\mathcal{B}}$.

Seja $\{M_{i}\}_{i \in \mathbb{N}}$ uma enumeração de todas máquinas de Turing de tempo polinomial e $\{p_{i}\}_{i \in \mathbb{N}}$ o tempo de execução de cada uma das $M_{i}s$.

Para $M_{1}$, escolhemos um número $n_{1}$ grande o suficiente de forma que $p_{1}(n_{1}) < 2^{n_{1}}$. Seja $q_{1}, q_{2}, \dots, q_{l}$, com $l < p_{1}(n_{1})$, as strings consultadas por $M_{1}$ na entrada $1^{n_{1}}$ e declaramos que cada $q_{i} \not\in \mathcal{B}$. Então,

\begin{itemize}

    \item Se $M_{1}(1^{n_{1}}) = 1 \Rightarrow$ declare todas as strings de tamanho $n_{1}$ como não estando em $\mathcal{B}$.
    
    \item Se $M_{1}(1^{n_{1}}) = 0 \Rightarrow$ declare pelo menos uma string não consultada por $M_{1}$ como estando em $\mathcal{B}$.

\end{itemize}

Como $p_{1}(n_{1}) < 2^{n_{1}}$ temos que tal string deve existir.

Para $i > 1$ nós fazemos a mesma coisa. Nós definimos $n_{i}$ como sendo o menor número em $\mathbb{N}$ tal que $p_{i}(n_{i}) < 2^{n_{i}}$ e $n_{i} > n_{i - 1}$. Como podemos assumir que nos passos anteriores nenhuma string de tamanho maior do que $n_{i - 1}$ já esteve sua pertinência em $\mathcal{B}$ resolvida, podemos proceder da mesma forma como fizemos no primeiro estágio.

Então, para cada $M_{i}$ nós descrevemos uma string $1^{n_{i}}$ tal que $M_{i}(1^{n_{i}}) = 1 \iff 1^{n_{i}} \not\in L_{\mathcal{B}}$. Portanto, nenhuma das máquinas de Turing de tempo polinomial $M_{i}$ é um decisor para $L_{\mathcal{B}}$ e consequentemente $L_{\mathcal{B}} \not\in \P^{\mathcal{B}}$.

\end{proof}

%\subsubsection{Hipótese do tempo exponencial e algoritmos para o problema SAT}

%A hipótese do tempo exponencia basicamente diz que força-bruta é o melhor que podemos fazer contra o problema CNF-SAT.

%\begin{ETH}

%Existe $\epsilon > 0$ tal que $3-SAT$ não é decidível em tempo $2^{\epsilon n}$.

%\end{ETH}

%E também temos a tua versão mais forte.

%\begin{SETH}

%Não existe $\delta < 1$ tal que $k$-SAT possa ser resolvido em tempo $2^{\delta n}$ para infinitos valores de $k$.

%\end{SETH}

%Assumindo que algoritmos eficientes para certo problemas computacionais existem, nós podemos falsificar a versão forte da hípotese do tempo exponencial, ou por outro lado, se assurmirmos que a ETH é verdadeira, limites inferiores para estes mesmos problemas seguem como consequência.

%Este tópico de algoritmos não-triviais para o problema da satisfibilidade e suas variantes aparecerá mais a frente neste trabalho. Por hora, nós vemos algumas estratégias para obter algoritmos não triviais para CNF-SAT.


