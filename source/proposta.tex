\chapter{Introdução}

O objetivo central da área de complexidade computacional é saber a dificuldade intrínseca de problemas computacionais, diferentemente de design de algoritmos que busca encontrar soluções eficientes para um problema. Quando falamos de complexidade de problemas computacionais estamos querendo dizer o recurso necessário para resolver tais problemas. 

Quando analisamos a complexidade de problemas computacionais nós devemos levar em conta o modelo computacional e o recurso em questão. Às vezes estamos interessados em avaliar o tempo necessário para computar um certo problema em uma máquina de acesso aleatório ou talvez o número de bits que dois processadores enviam um ao outro. Alguns resultados antigos mostraram que dar mais tempo ou espaço para máquinas de Turing aumenta o número de problemas que elas podem resolver, porém estes resultados não apresentaram limites inferiores para problemas naturais~\cite{arora2009computational}. Meyer e Stockmeyer provaram que certos problemas são completos para a classe de problemas que necessitam de tempo exponencial em máquinas de Turing~\cite{beyondNP}, o que também significa que estes problemas não podem ser decididos em tempo polinomial. O limite inferior de $\Omega(nlogn)$ passos para algoritmos de ordenação de lista que usa comparações é um exemplo de limite inferior em algoritmos.

Em complexidade de circuitos procura-se saber o tamanho ou profundidade dos circuitos necessários para decidir uma linguagem. Circuitos booleanos são matematicamente mais simples do que máquinas de Turing e alguns resultados em complexidade de circuitos resolveriam também problemas em aberto em outros modelos de computação. Como exemplo, se conseguirmos provar que problemas que são fáceis de se verificar uma solução não têm circuitos de tamanho polinomial ($\NP \nsubseteq \Ppoly$) então $\P \neq \NP$. Porém, provar que $\NP \nsubseteq \Ppoly$ é extremamente dificil e por isso o foco de pesquisa hoje em dia é provar problemas mais fracos, na maioria das vezes restrigindo a classe de circuitos (como por exemplo, circuitos de profundidade logaritmica). Nos anos 80 houve avanços nesse sentido quando pesquisadores conseguiram mostrar que certos problemas não podiam ser decididos por classes mais restritas de circuitos. No entanto, em 1994, Razborov e Rudich mostraram que, sob algumas hipóteses de complexidade computacional, as técnicas usadas até então para provar limites inferiores, as quais eles chamaram de provas naturais, não seriam suficiente para provar que $\P \neq \NP$~\cite{natural}. E por isso, para que qualquer estratégia de prova possa ser levada a frente é necessário de alguma forma passar pelas limitações das provas naturais.

Nos últimos anos, novos limites inferiores em complexidade de circuitos foram obtidos usando uma estratégia de prova que liga algoritmos ``rápidos''  a limite inferiores ~\cite{RW1, RW2}.  Para uma determinada classe de circuitos $C$, se você conseguir mostrar que o problema $C$--$\SAT$ (o problema de avaliar se um circuito em $C$ não computa a função $f(x) = 0$, para todo $x$) tem um algoritmo mais rápido do que o algoritmo mais óbvio (tentar todas as $2^n$ entradas possíveis), então você consegue mostrar que a classe de problemas cuja uma solução pode ser verificada em tempo exponencial ($\NEXP$) não tem circuitos em $C$. Estudar a conexão entre algoritmos e limites inferiores em circuitos booleanos é um assunto interessante para alguém que deseja realizar pesquisas em complexidade computacional.

\section{Objetivo}

Este trabalho visa apresentar um estudo teórico acerca da área de complexidade de circuitos e suas aplicações ao estudo da complexidade computacional. Primeiramente será feito um estudo sobre complexidade computacional. Depois serão pesquisados tópicos em complexidades de circuitos com foco principal nos tópicos mais recentes e ferramentas/técnicas comumente usadas em provas em complexidade de circuitos.
